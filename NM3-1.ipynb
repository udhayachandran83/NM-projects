{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVtqjHvhUXnf",
    "outputId": "792c6971-5228-471a-a892-9da1c27112a4"
   },
   "outputs": [],
   "source": [
    "!pip install librosa pandas matplotlib seaborn soundfile jiwer \\\n",
    "transformers torchaudio wordcloud datasets scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8k3T0SaVkrF",
    "outputId": "259eea35-97a2-45d4-8884-55659b798014"
   },
   "outputs": [],
   "source": [
    "!pip install fsspec==2025.3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1qvb-iAVrMO",
    "outputId": "814c093a-9baf-4654-810b-5f89331e5655"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Create a directory for the dataset\n",
    "dataset_url = \"https://www.openslr.org/resources/12/dev-clean.tar.gz\"\n",
    "dataset_dir = \"/content/LibriSpeech\"\n",
    "archive_path = \"/content/dev-clean.tar.gz\"\n",
    "\n",
    "# Download the dataset\n",
    "urllib.request.urlretrieve(dataset_url, archive_path)\n",
    "\n",
    "# Extract the dataset\n",
    "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=dataset_dir)\n",
    "\n",
    "print(\"Dataset extracted to:\", dataset_dir)\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Create a directory for the dataset\n",
    "dataset_url = \"https://www.openslr.org/resources/12/dev-clean.tar.gz\"\n",
    "dataset_dir = \"/content/LibriSpeech\"\n",
    "archive_path = \"/content/dev-clean.tar.gz\"\n",
    "\n",
    "# Download the dataset\n",
    "urllib.request.urlretrieve(dataset_url, archive_path)\n",
    "\n",
    "# Extract the dataset\n",
    "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=dataset_dir)\n",
    "\n",
    "print(\"Dataset extracted to:\", dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYavdgQDWfnO",
    "outputId": "0742240b-00df-47c1-9d1d-f53bfe8bbade"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List a few .flac audio files\n",
    "flac_files = sorted(glob.glob(dataset_dir + \"/LibriSpeech/dev-clean/**/**/*.flac\", recursive=True))\n",
    "print(\"Number of audio files:\", len(flac_files))\n",
    "print(\"Sample file path:\", flac_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Edy5gOWTWpBO",
    "outputId": "7258ef99-33b5-4932-e1dd-b5cb364ef3b3"
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "# Convert first .flac to .wav\n",
    "wav_output = \"/content/sample.wav\"\n",
    "data, samplerate = sf.read(flac_files[0])\n",
    "sf.write(wav_output, data, samplerate)\n",
    "print(\"Converted to WAV:\", wav_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "AlS0UnstWs6t",
    "outputId": "f9992d7c-7394-4135-a619-ef2bd421c4fb"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Load the audio\n",
    "y, sr = librosa.load(wav_output, sr=16000)\n",
    "\n",
    "# Display audio\n",
    "Audio(wav_output)\n",
    "\n",
    "# Waveform\n",
    "plt.figure(figsize=(10, 3))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title('Waveform')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7_kck6oQUPh"
   },
   "outputs": [],
   "source": [
    "!pip install librosa soundfile tqdm --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrNZFjmiQX4Z",
    "outputId": "301c7fb5-de1f-47b0-95c0-5cda36433438"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://www.openslr.org/resources/12/dev-clean.tar.gz\"\n",
    "data_dir = \"/content/LibriSpeech\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Download\n",
    "archive_path = os.path.join(data_dir, \"dev-clean.tar.gz\")\n",
    "urllib.request.urlretrieve(url, archive_path)\n",
    "\n",
    "# Extract\n",
    "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=data_dir)\n",
    "\n",
    "print(\"✅ Dataset ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "eabYcYzHQkOx",
    "outputId": "b7d0e590-dd4d-4edf-a9f6-933fc35a8335"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "wav_paths = []\n",
    "transcripts = []\n",
    "\n",
    "# Look inside all folders\n",
    "for root, _, files in os.walk(f\"{data_dir}/LibriSpeech/dev-clean\"):\n",
    "    trans_files = [f for f in files if f.endswith(\".trans.txt\")]\n",
    "    for tf in trans_files:\n",
    "        trans_path = os.path.join(root, tf)\n",
    "        with open(trans_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split(\" \", 1)\n",
    "                file_id = parts[0]\n",
    "                transcript = parts[1]\n",
    "                flac_path = os.path.join(root, file_id + \".flac\")\n",
    "                if os.path.exists(flac_path):\n",
    "                    wav_paths.append(flac_path)\n",
    "                    transcripts.append(transcript)\n",
    "\n",
    "df = pd.DataFrame({\"wav_path\": wav_paths, \"transcript\": transcripts})\n",
    "print(f\"✅ Found {len(df)} audio files.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxZYe3npQmux",
    "outputId": "c01e1951-08de-49b4-8898-6392d75fb8e9"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfcc.T  # time x features\n",
    "\n",
    "# Test MFCC extraction\n",
    "sample_mfcc = extract_mfcc(df.iloc[0]['wav_path'])\n",
    "print(\"MFCC shape:\", sample_mfcc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "conCSFm6RCGg",
    "outputId": "616b6b8f-7f0f-4b97-a641-14794c185aca"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfcc.T  # transpose to shape: (time, features)\n",
    "\n",
    "# Example for one file\n",
    "mfcc_features = extract_mfcc(df.iloc[0]['wav_path'])\n",
    "print(mfcc_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JuMGwZSRT5Z",
    "outputId": "77bd777e-a0a6-49b3-a425-9a7c675e2ebb"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Character-level encoding (more flexible for unknown words)\n",
    "all_text = \" \".join(df[\"transcript\"]).lower()\n",
    "chars = sorted(list(set(all_text)))\n",
    "\n",
    "char_encoder = LabelEncoder()\n",
    "char_encoder.fit(list(chars))\n",
    "\n",
    "def text_to_int_sequence(text):\n",
    "    return char_encoder.transform(list(text.lower()))\n",
    "\n",
    "# Example\n",
    "encoded = text_to_int_sequence(df.iloc[0][\"transcript\"])\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZZTQ6dbRVv5"
   },
   "outputs": [],
   "source": [
    "X = []  # features (MFCCs)\n",
    "y = []  # labels (text)\n",
    "\n",
    "for i in range(100):  # smaller subset for initial training\n",
    "    mfcc = extract_mfcc(df.iloc[i][\"wav_path\"])\n",
    "    label = text_to_int_sequence(df.iloc[i][\"transcript\"])\n",
    "    X.append(mfcc)\n",
    "    y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtMgPNsGRZeR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_pad = pad_sequences(X, padding=\"post\", dtype=\"float32\")\n",
    "y_pad = pad_sequences(y, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c3J5oTWRf3J",
    "outputId": "2216b735-6410-40af-9fe8-8246faa5d5d1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(X_pad.shape[1], X_pad.shape[2])),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(char_encoder.classes_), activation='softmax')  # output is per character\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Use y_pad[:, 0] for simplified training (first character only)\n",
    "model.fit(X_pad, y_pad[:, 0], epochs=5, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqGxWZvhR1E6",
    "outputId": "738e8fd4-f065-4c23-f1fa-e2114d7057c6"
   },
   "outputs": [],
   "source": [
    "# Predict on one sample\n",
    "pred = model.predict(X_pad[0:1])\n",
    "pred_char = char_encoder.inverse_transform([np.argmax(pred[0])])\n",
    "print(\"Predicted character:\", pred_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "-oaKWItLVlcy",
    "outputId": "04e59709-e993-4687-8a3e-66e0a0d4cbd4"
   },
   "outputs": [],
   "source": [
    "subset_df = df.head(2)  # Just take first 2 files\n",
    "\n",
    "results = []\n",
    "for i in range(len(subset_df)):\n",
    "    audio_path = subset_df.iloc[i]['wav_path']\n",
    "    try:\n",
    "        result = asr(audio_path)\n",
    "        results.append({\n",
    "            \"file\": audio_path,\n",
    "            \"ground_truth\": subset_df.iloc[i]['transcript'],\n",
    "            \"prediction\": result[\"text\"].strip().lower()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {audio_path}: {e}\")\n",
    "\n",
    "transcribed_df = pd.DataFrame(results)\n",
    "transcribed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN1QuHrKVysb",
    "outputId": "ebebc554-9ecf-44e5-cfcd-80bfac05afed"
   },
   "outputs": [],
   "source": [
    "asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386,
     "referenced_widgets": [
      "3b2203b7579a4673bd2bc0d96b13dcb4",
      "603220b0d1c245599d3bfd788c327629",
      "63fbd0f7567148218b538c3b777499b4",
      "0cd5103cdc4b4a8cab81f2f46cc6dc81",
      "76a4cad5a9484e93bef81bb40d378dfc",
      "6f0817cf63bb4233a9fac9a10374d421",
      "99255740909c412684668db018891d6c",
      "9d09ac148d6241ebbc71faf5132ad50e",
      "753f5750e6004f2593acfd280e7bcb20",
      "a749b8d28d3e4deaad4461b3647ad20d",
      "d82b6f3f94da4fc6bb024fa50dc93d3a",
      "7ed7435640934179ad7905a949603fef",
      "15800210467a426480371636d5525c36",
      "7fc2e549be2e4e9bbf152955b6b00d1c",
      "7b5ac5f735fc49ec96a99441c3e1b6fb",
      "5ebf9f21445d47f6a0c235f74ce106d2",
      "7ad89a37fede48fda2afd39d75dce5f6",
      "5259765a49a54c1f90653e77c9d030bc",
      "5f7f6a5eb3164e85a6b99fc06c7fe32c",
      "4fe0adbd2a5f41b2bf6c738557a30adb",
      "15ae40955cf4459791ec37bd93483bc9",
      "cbea73a1cde846f8b3cfdfa5385c6edc",
      "af743368545d4427a5618a0333143cad",
      "806c41ab62304472a0ad3666141c8b65",
      "69a20a8b272849f88745078086e8e2d2",
      "9eac290d253b47eebf693f2c29d8c360",
      "b654e22625414925900153c33b898d53",
      "3226439a589148069c5801001e2af426",
      "947e5cb42c004e90bb0b498005bffa28",
      "dea37fff0dab4cfa82b156492dda93bf",
      "2755cb3ca34442c89bb80673c0f4edda",
      "53295bf197b741d2b5ba7587a71b8ce6",
      "ef18bc498147430f8d5b18b824964975",
      "d1dd7016b0a141e38e6a03c3f83efe0e",
      "c23ac66a79ea479c901c95de43ac2131",
      "4d44f4284de245a1a14095f1d34b6176",
      "5dbfcc21faf945cd8a21b65b02401012",
      "21c3ff4ff6274faebf2f00e9cfc52d68",
      "42609cf96e78427cb441970a3d8b7304",
      "5da01ca867d94815a9fda85435014d20",
      "087dd24d54b94a70ae7500f76952fce3",
      "d87299ff80254b1f8246d2ae1d2e18da",
      "8683b4e27571453aab77872f12fc3d1d",
      "dce68a252e474aa49b582c2dfdb60f47",
      "eb93a0129a1e4a6cab2ce8d8ecd2a3c1",
      "e75b97d10b07408585fa65c650d8f041",
      "013617814d8e46418a4a8cdbcbf6470e",
      "284938b9e5734c32bbc1ac21894f3e28",
      "6b3ea68002094990bb120b4291dfc8f3",
      "1f5d1d39e6c445b593d5044853e4ce83",
      "b01c8e07061949c89addaef2b44091e9",
      "16869271a67642499e95078f9579a5f7",
      "7ea3ea702ef14bffb947ebf3d0ef524b",
      "f8b1c1356044499f9c3473c176b1b37a",
      "6e195bc4e1994f8e8c98f57bcf992a0d",
      "6a7181d3d2b841f4a35a6079a1cd8927",
      "1962dedcc8494b9094777c68b942c568",
      "eb13a9e584094efd9a5ed86719fde461",
      "a006795e4ab7442aa5248f505ccfe41f",
      "34782243b54c444aa84b1ef60c5d2c50",
      "6074b2139ae44ce19668bfa5a30995e2",
      "d03ac64e06ba48f69fa5456edb43e5f7",
      "7a4aa4e60db84a7fae1c8f64316f85bb",
      "e1ca24bf75344eef9331da2d88aef4f5",
      "5a122a91e3c74b14b9aed8f627a00edf",
      "03b296c3d8ac4401965586298d71172e",
      "928645b58b6444e5811b6c7e088f11ce",
      "c303c7dbeb5649a19bc40de05be72ad7",
      "68cf4298e9b34a8d9afc6e69b97b8db6",
      "ce95e0a0d7d047a2aa391ddf56c64ccd",
      "38f6a942b37f4838939074ac1d0b49ad",
      "789d67008c704d1b8b7ceba3b3dc120e",
      "93ece7d1cabf4c5fb36e9ac2dd7e8173",
      "f610dbc62b934923bd8aba4eabe9f1f3",
      "df1ff3a03fca419b84e82574b069bcab",
      "f9675d858e4d4c2cb97981ac0d70e178",
      "71aaea531a344609ad5f9f847c5f5c39",
      "55bc06a1a4924ad4b591bd6245633c25",
      "1fffc997a7954d0ea2c225df0535ecf7",
      "db5369e2657447bb9cf5b91369e38be0",
      "ca99415e878847c494a024fb658a3d48",
      "e1d2582edfc74feb8d0cc34fed763433",
      "b854aef08bf140ffa94f5d840e1173c6",
      "581cd397b2334a34ac09fd16534a29a0",
      "d86cf0fa07a947faa49e32117ee2040f",
      "e6aebe52102a4370baf3bf101bf06e1d",
      "3f719f76400140f68a64aa84b1159f0b",
      "c6d2000cf5924c40aa9034fb0483350d",
      "f573f12e255146ef974cc52d4dcb4603",
      "d7239b1a0b8b4cbe86caae5eb451cb6c",
      "eab606cbd89844b9a4350e491e6ee2a5",
      "b67c6cfa396b4cd1bc44224cd946e983",
      "5c460b4d2ba34b71b1c0fa665cba9cae",
      "e48b4a3eb83547eeb91542eab510bc93",
      "b7c50f90754f4684af7fc5da2fded29c",
      "d7330e614dcc42a8bf75b62f04b4c5f3",
      "23a7664ae914469bb76c572fc11a42be",
      "ca49cc9722fc42a0af198cb650756cc8",
      "885e8e71026c4f86baec45127e3f83ff",
      "fa8bcb4f510b4e099be1768b65373337",
      "398d62ec3a124d1e9e411c3a4dad33ef",
      "55d856e227294bd5af51269d6993c993",
      "0bf15ff49eba43beb4a374760c23b631",
      "9e1d43825b054776879fefcbd9a56d91",
      "eba307ad8e624cdf90a6a0e35aecea3a",
      "9a50e7032ec84af99ca4556477f5aea9",
      "bd85a66bc2464fca82304c2d64c0879c",
      "8add81209e174191b3dbb2d6e152b585",
      "64960d908b58438bbb91398fecca270f",
      "98fb46b2995849f4a9f4d976671e2436",
      "a6a2eb1e82b44056b40e07384c4b9898",
      "2ab6796cede44935b7dc624163181233",
      "b97a03b676b2486b9d940883f4b36464",
      "0b9334329baa4ad584e17460e9dfa4b9",
      "4b035acd5d4c4beaa20f45cd10657d32",
      "dac3da7204fc4840852b4a39093cf679",
      "208c07b55c4f49e7ac43375fe1a683c8",
      "4122fa55ded24b6dbfe0f488a48eedfd",
      "fb83b59f999a4de585894519386b9c4b",
      "ba9f62b4b6c74742be649fbd847510d6",
      "0cc7e890a59a4f2593c1d0552023dde8"
     ]
    },
    "id": "vJR5nPwoV7QS",
    "outputId": "bafb41a5-2dc0-4e13-968a-1f8e83394caf"
   },
   "outputs": [],
   "source": [
    "asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-tiny\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "M_CDOcz5WCsJ",
    "outputId": "7d3b38d9-e852-471f-990d-cfef3ea88b71"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get uploaded file path\n",
    "import os\n",
    "audio_path = next(iter(uploaded))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
